{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Crop_recommendation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>20.879744</td>\n",
       "      <td>82.002744</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>202.935536</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>21.770462</td>\n",
       "      <td>80.319644</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>226.655537</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>23.004459</td>\n",
       "      <td>82.320763</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>263.964248</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>26.491096</td>\n",
       "      <td>80.158363</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>242.864034</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>20.130175</td>\n",
       "      <td>81.604873</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>262.717340</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N   P   K  temperature   humidity        ph    rainfall label\n",
       "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
       "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
       "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
       "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
       "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N              0\n",
       "P              0\n",
       "K              0\n",
       "temperature    0\n",
       "humidity       0\n",
       "ph             0\n",
       "rainfall       0\n",
       "label          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "rice           100\n",
       "maize          100\n",
       "chickpea       100\n",
       "kidneybeans    100\n",
       "pigeonpeas     100\n",
       "mothbeans      100\n",
       "mungbean       100\n",
       "blackgram      100\n",
       "lentil         100\n",
       "pomegranate    100\n",
       "banana         100\n",
       "mango          100\n",
       "grapes         100\n",
       "watermelon     100\n",
       "muskmelon      100\n",
       "apple          100\n",
       "orange         100\n",
       "papaya         100\n",
       "coconut        100\n",
       "cotton         100\n",
       "jute           100\n",
       "coffee         100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x= pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3    4    5    6    7    8    9   ...   12   13   14  \\\n",
      "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "2195  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2196  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2197  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2198  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2199  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "       15   16   17   18   19   20   21  \n",
      "0     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "1     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "2     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "3     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "4     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "2195  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2196  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2197  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2198  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2199  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2200 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "y = pd.DataFrame(Encoder.fit_transform(data[['label']]).toarray())\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split with stratification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "#Creating the model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # First hidden layer\n",
    "    Dense(32, activation='relu'),  # Second hidden layer\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - accuracy: 0.0914 - loss: 3.0184 - val_accuracy: 0.3153 - val_loss: 2.6611\n",
      "Epoch 2/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3632 - loss: 2.5695 - val_accuracy: 0.5369 - val_loss: 2.1108\n",
      "Epoch 3/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 2.0051 - val_accuracy: 0.6705 - val_loss: 1.4650\n",
      "Epoch 4/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7400 - loss: 1.3607 - val_accuracy: 0.8466 - val_loss: 0.9170\n",
      "Epoch 5/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.8797 - val_accuracy: 0.8750 - val_loss: 0.6270\n",
      "Epoch 6/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8910 - loss: 0.5901 - val_accuracy: 0.8835 - val_loss: 0.4846\n",
      "Epoch 7/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9058 - loss: 0.4586 - val_accuracy: 0.9034 - val_loss: 0.3829\n",
      "Epoch 8/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.3671 - val_accuracy: 0.9034 - val_loss: 0.3297\n",
      "Epoch 9/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.2973 - val_accuracy: 0.9176 - val_loss: 0.2764\n",
      "Epoch 10/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.2508 - val_accuracy: 0.9233 - val_loss: 0.2458\n",
      "Epoch 11/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9473 - loss: 0.2312 - val_accuracy: 0.9375 - val_loss: 0.2162\n",
      "Epoch 12/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9517 - loss: 0.2023 - val_accuracy: 0.9432 - val_loss: 0.1978\n",
      "Epoch 13/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1813 - val_accuracy: 0.9517 - val_loss: 0.1775\n",
      "Epoch 14/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1648 - val_accuracy: 0.9545 - val_loss: 0.1597\n",
      "Epoch 15/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.1379 - val_accuracy: 0.9574 - val_loss: 0.1472\n",
      "Epoch 16/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9690 - loss: 0.1347 - val_accuracy: 0.9602 - val_loss: 0.1406\n",
      "Epoch 17/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.1318 - val_accuracy: 0.9574 - val_loss: 0.1375\n",
      "Epoch 18/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9594 - loss: 0.1313 - val_accuracy: 0.9574 - val_loss: 0.1237\n",
      "Epoch 19/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.1139 - val_accuracy: 0.9602 - val_loss: 0.1171\n",
      "Epoch 20/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1182 - val_accuracy: 0.9659 - val_loss: 0.1104\n",
      "Epoch 21/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0957 - val_accuracy: 0.9716 - val_loss: 0.1032\n",
      "Epoch 22/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9799 - loss: 0.0868 - val_accuracy: 0.9631 - val_loss: 0.0983\n",
      "Epoch 23/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9786 - loss: 0.0891 - val_accuracy: 0.9716 - val_loss: 0.0976\n",
      "Epoch 24/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9704 - loss: 0.0990 - val_accuracy: 0.9801 - val_loss: 0.0929\n",
      "Epoch 25/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9813 - loss: 0.0773 - val_accuracy: 0.9659 - val_loss: 0.0889\n",
      "Epoch 26/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9674 - loss: 0.0892 - val_accuracy: 0.9773 - val_loss: 0.0878\n",
      "Epoch 27/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9793 - loss: 0.0718 - val_accuracy: 0.9773 - val_loss: 0.0857\n",
      "Epoch 28/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9777 - loss: 0.0753 - val_accuracy: 0.9716 - val_loss: 0.0815\n",
      "Epoch 29/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9803 - loss: 0.0730 - val_accuracy: 0.9773 - val_loss: 0.0806\n",
      "Epoch 30/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0626 - val_accuracy: 0.9744 - val_loss: 0.0767\n",
      "Epoch 31/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9752 - loss: 0.0754 - val_accuracy: 0.9801 - val_loss: 0.0775\n",
      "Epoch 32/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0734 - val_accuracy: 0.9801 - val_loss: 0.0736\n",
      "Epoch 33/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0635 - val_accuracy: 0.9716 - val_loss: 0.0736\n",
      "Epoch 34/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.0702 - val_accuracy: 0.9773 - val_loss: 0.0704\n",
      "Epoch 35/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0571 - val_accuracy: 0.9744 - val_loss: 0.0683\n",
      "Epoch 36/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0492 - val_accuracy: 0.9744 - val_loss: 0.0646\n",
      "Epoch 37/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0624 - val_accuracy: 0.9744 - val_loss: 0.0651\n",
      "Epoch 38/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0534 - val_accuracy: 0.9744 - val_loss: 0.0665\n",
      "Epoch 39/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0517 - val_accuracy: 0.9744 - val_loss: 0.0655\n",
      "Epoch 40/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0444 - val_accuracy: 0.9830 - val_loss: 0.0586\n",
      "Epoch 41/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9856 - loss: 0.0539 - val_accuracy: 0.9801 - val_loss: 0.0588\n",
      "Epoch 42/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0414 - val_accuracy: 0.9744 - val_loss: 0.0598\n",
      "Epoch 43/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9891 - loss: 0.0445 - val_accuracy: 0.9716 - val_loss: 0.0631\n",
      "Epoch 44/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0504 - val_accuracy: 0.9688 - val_loss: 0.0674\n",
      "Epoch 45/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 0.0448 - val_accuracy: 0.9744 - val_loss: 0.0612\n",
      "Epoch 46/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0408 - val_accuracy: 0.9773 - val_loss: 0.0581\n",
      "Epoch 47/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0354 - val_accuracy: 0.9858 - val_loss: 0.0557\n",
      "Epoch 48/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0458 - val_accuracy: 0.9858 - val_loss: 0.0512\n",
      "Epoch 49/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0365 - val_accuracy: 0.9744 - val_loss: 0.0541\n",
      "Epoch 50/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0378 - val_accuracy: 0.9773 - val_loss: 0.0519\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f1eb251060>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "#  Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "[[8.25868020e-13 2.59187316e-09 3.73228837e-10 ... 9.86852202e-13\n",
      "  2.19966401e-04 1.01752903e-06]\n",
      " [1.04295905e-13 1.71580090e-13 2.45915430e-13 ... 3.52373520e-15\n",
      "  9.99595702e-01 3.41047957e-14]\n",
      " [5.11191054e-08 2.50740900e-10 7.11409881e-12 ... 4.41760320e-04\n",
      "  2.84619962e-12 4.77770939e-02]\n",
      " ...\n",
      " [6.79024892e-11 4.26087965e-09 2.71334685e-03 ... 2.55919161e-08\n",
      "  2.87780433e-12 4.79926446e-11]\n",
      " [1.18575887e-08 1.81390555e-10 5.47384188e-05 ... 2.67276445e-09\n",
      "  1.51736229e-14 5.94951809e-14]\n",
      " [7.63595173e-16 1.11962365e-14 1.89203375e-11 ... 1.34898061e-12\n",
      "  3.93320995e-19 3.40093643e-12]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        20\n",
      "      banana       1.00      1.00      1.00        20\n",
      "   blackgram       0.95      1.00      0.98        20\n",
      "    chickpea       1.00      1.00      1.00        20\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       0.95      1.00      0.98        20\n",
      "      cotton       1.00      1.00      1.00        20\n",
      "      grapes       1.00      1.00      1.00        20\n",
      "        jute       1.00      0.70      0.82        20\n",
      " kidneybeans       1.00      1.00      1.00        20\n",
      "      lentil       1.00      1.00      1.00        20\n",
      "       maize       1.00      1.00      1.00        20\n",
      "       mango       1.00      1.00      1.00        20\n",
      "   mothbeans       1.00      0.95      0.97        20\n",
      "    mungbean       1.00      1.00      1.00        20\n",
      "   muskmelon       1.00      0.95      0.97        20\n",
      "      orange       1.00      1.00      1.00        20\n",
      "      papaya       1.00      0.95      0.97        20\n",
      "  pigeonpeas       1.00      1.00      1.00        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       0.77      1.00      0.87        20\n",
      "  watermelon       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.98       440\n",
      "   macro avg       0.98      0.98      0.98       440\n",
      "weighted avg       0.98      0.98      0.98       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "# Get predictions for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = np.argmax(y_test, axis=1)  # Convert one-hot encoding to class labels\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test_classes, y_pred_classes, target_names=Encoder.categories_[0])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'banana', 'blackgram', 'chickpea', 'coconut', 'coffee',\n",
       "       'cotton', 'grapes', 'jute', 'kidneybeans', 'lentil', 'maize',\n",
       "       'mango', 'mothbeans', 'mungbean', 'muskmelon', 'orange', 'papaya',\n",
       "       'pigeonpeas', 'pomegranate', 'rice', 'watermelon'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
