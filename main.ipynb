{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Crop_recommendation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>20.879744</td>\n",
       "      <td>82.002744</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>202.935536</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>21.770462</td>\n",
       "      <td>80.319644</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>226.655537</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>23.004459</td>\n",
       "      <td>82.320763</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>263.964248</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>26.491096</td>\n",
       "      <td>80.158363</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>242.864034</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>20.130175</td>\n",
       "      <td>81.604873</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>262.717340</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N   P   K  temperature   humidity        ph    rainfall label\n",
       "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
       "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
       "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
       "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
       "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N              0\n",
       "P              0\n",
       "K              0\n",
       "temperature    0\n",
       "humidity       0\n",
       "ph             0\n",
       "rainfall       0\n",
       "label          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "rice           100\n",
       "maize          100\n",
       "chickpea       100\n",
       "kidneybeans    100\n",
       "pigeonpeas     100\n",
       "mothbeans      100\n",
       "mungbean       100\n",
       "blackgram      100\n",
       "lentil         100\n",
       "pomegranate    100\n",
       "banana         100\n",
       "mango          100\n",
       "grapes         100\n",
       "watermelon     100\n",
       "muskmelon      100\n",
       "apple          100\n",
       "orange         100\n",
       "papaya         100\n",
       "coconut        100\n",
       "cotton         100\n",
       "jute           100\n",
       "coffee         100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:, :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x= pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3    4    5    6    7    8    9   ...   12   13   14  \\\n",
      "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "2195  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2196  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2197  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2198  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2199  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "       15   16   17   18   19   20   21  \n",
      "0     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "1     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "2     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "3     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "4     0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "2195  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2196  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2197  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2198  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2199  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[2200 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "y = pd.DataFrame(Encoder.fit_transform(data[['label']]).toarray())\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split with stratification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\Crop Prediction\\crop\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "#Creating the model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),  # First hidden layer\n",
    "    Dense(32, activation='relu'),  # Second hidden layer\n",
    "    Dense(y_train.shape[1], activation='softmax')  # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.0912 - loss: 3.0367 - val_accuracy: 0.2756 - val_loss: 2.6971\n",
      "Epoch 2/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3495 - loss: 2.6186 - val_accuracy: 0.4602 - val_loss: 2.1608\n",
      "Epoch 3/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4896 - loss: 2.0518 - val_accuracy: 0.6278 - val_loss: 1.5988\n",
      "Epoch 4/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6342 - loss: 1.5662 - val_accuracy: 0.7244 - val_loss: 1.1308\n",
      "Epoch 5/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7853 - loss: 1.0587 - val_accuracy: 0.8580 - val_loss: 0.7779\n",
      "Epoch 6/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8827 - loss: 0.7442 - val_accuracy: 0.8722 - val_loss: 0.5686\n",
      "Epoch 7/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9124 - loss: 0.5267 - val_accuracy: 0.8920 - val_loss: 0.4476\n",
      "Epoch 8/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9249 - loss: 0.4189 - val_accuracy: 0.9062 - val_loss: 0.3606\n",
      "Epoch 9/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.3475 - val_accuracy: 0.9261 - val_loss: 0.3055\n",
      "Epoch 10/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9252 - loss: 0.3005 - val_accuracy: 0.9148 - val_loss: 0.2748\n",
      "Epoch 11/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9376 - loss: 0.2420 - val_accuracy: 0.9233 - val_loss: 0.2513\n",
      "Epoch 12/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9533 - loss: 0.2206 - val_accuracy: 0.9517 - val_loss: 0.2096\n",
      "Epoch 13/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9630 - loss: 0.1881 - val_accuracy: 0.9432 - val_loss: 0.1958\n",
      "Epoch 14/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9612 - loss: 0.1790 - val_accuracy: 0.9347 - val_loss: 0.1801\n",
      "Epoch 15/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9578 - loss: 0.1685 - val_accuracy: 0.9574 - val_loss: 0.1623\n",
      "Epoch 16/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9633 - loss: 0.1438 - val_accuracy: 0.9545 - val_loss: 0.1463\n",
      "Epoch 17/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9633 - loss: 0.1447 - val_accuracy: 0.9631 - val_loss: 0.1438\n",
      "Epoch 18/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.1227 - val_accuracy: 0.9659 - val_loss: 0.1291\n",
      "Epoch 19/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9687 - loss: 0.1182 - val_accuracy: 0.9659 - val_loss: 0.1230\n",
      "Epoch 20/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9762 - loss: 0.1122 - val_accuracy: 0.9574 - val_loss: 0.1202\n",
      "Epoch 21/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.1074 - val_accuracy: 0.9631 - val_loss: 0.1102\n",
      "Epoch 22/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9634 - loss: 0.1183 - val_accuracy: 0.9602 - val_loss: 0.1046\n",
      "Epoch 23/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9760 - loss: 0.0987 - val_accuracy: 0.9631 - val_loss: 0.1026\n",
      "Epoch 24/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.0983 - val_accuracy: 0.9659 - val_loss: 0.1013\n",
      "Epoch 25/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9749 - loss: 0.0886 - val_accuracy: 0.9744 - val_loss: 0.0917\n",
      "Epoch 26/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.0881 - val_accuracy: 0.9716 - val_loss: 0.0899\n",
      "Epoch 27/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0784 - val_accuracy: 0.9688 - val_loss: 0.0889\n",
      "Epoch 28/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9776 - loss: 0.0803 - val_accuracy: 0.9801 - val_loss: 0.0839\n",
      "Epoch 29/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9753 - loss: 0.0784 - val_accuracy: 0.9716 - val_loss: 0.0826\n",
      "Epoch 30/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.0767 - val_accuracy: 0.9801 - val_loss: 0.0795\n",
      "Epoch 31/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9807 - loss: 0.0671 - val_accuracy: 0.9716 - val_loss: 0.0805\n",
      "Epoch 32/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.0726 - val_accuracy: 0.9744 - val_loss: 0.0746\n",
      "Epoch 33/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9847 - loss: 0.0619 - val_accuracy: 0.9801 - val_loss: 0.0714\n",
      "Epoch 34/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9758 - loss: 0.0737 - val_accuracy: 0.9801 - val_loss: 0.0730\n",
      "Epoch 35/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9814 - loss: 0.0689 - val_accuracy: 0.9744 - val_loss: 0.0749\n",
      "Epoch 36/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9777 - loss: 0.0615 - val_accuracy: 0.9801 - val_loss: 0.0660\n",
      "Epoch 37/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9823 - loss: 0.0598 - val_accuracy: 0.9858 - val_loss: 0.0664\n",
      "Epoch 38/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.0610 - val_accuracy: 0.9744 - val_loss: 0.0678\n",
      "Epoch 39/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9887 - loss: 0.0504 - val_accuracy: 0.9830 - val_loss: 0.0665\n",
      "Epoch 40/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9871 - loss: 0.0475 - val_accuracy: 0.9801 - val_loss: 0.0628\n",
      "Epoch 41/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9884 - loss: 0.0509 - val_accuracy: 0.9801 - val_loss: 0.0611\n",
      "Epoch 42/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9868 - loss: 0.0525 - val_accuracy: 0.9858 - val_loss: 0.0577\n",
      "Epoch 43/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9856 - loss: 0.0581 - val_accuracy: 0.9801 - val_loss: 0.0592\n",
      "Epoch 44/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9870 - loss: 0.0510 - val_accuracy: 0.9858 - val_loss: 0.0589\n",
      "Epoch 45/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9920 - loss: 0.0418 - val_accuracy: 0.9886 - val_loss: 0.0579\n",
      "Epoch 46/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9846 - loss: 0.0526 - val_accuracy: 0.9830 - val_loss: 0.0554\n",
      "Epoch 47/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9818 - loss: 0.0558 - val_accuracy: 0.9801 - val_loss: 0.0565\n",
      "Epoch 48/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0442 - val_accuracy: 0.9801 - val_loss: 0.0546\n",
      "Epoch 49/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9907 - loss: 0.0429 - val_accuracy: 0.9801 - val_loss: 0.0519\n",
      "Epoch 50/50\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0449 - val_accuracy: 0.9858 - val_loss: 0.0536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a100d8fc40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('crop_recommendation_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "#  Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "[[8.25868020e-13 2.59187316e-09 3.73228837e-10 ... 9.86852202e-13\n",
      "  2.19966401e-04 1.01752903e-06]\n",
      " [1.04295905e-13 1.71580090e-13 2.45915430e-13 ... 3.52373520e-15\n",
      "  9.99595702e-01 3.41047957e-14]\n",
      " [5.11191054e-08 2.50740900e-10 7.11409881e-12 ... 4.41760320e-04\n",
      "  2.84619962e-12 4.77770939e-02]\n",
      " ...\n",
      " [6.79024892e-11 4.26087965e-09 2.71334685e-03 ... 2.55919161e-08\n",
      "  2.87780433e-12 4.79926446e-11]\n",
      " [1.18575887e-08 1.81390555e-10 5.47384188e-05 ... 2.67276445e-09\n",
      "  1.51736229e-14 5.94951809e-14]\n",
      " [7.63595173e-16 1.11962365e-14 1.89203375e-11 ... 1.34898061e-12\n",
      "  3.93320995e-19 3.40093643e-12]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        20\n",
      "      banana       1.00      1.00      1.00        20\n",
      "   blackgram       0.95      1.00      0.98        20\n",
      "    chickpea       1.00      1.00      1.00        20\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       0.95      1.00      0.98        20\n",
      "      cotton       1.00      1.00      1.00        20\n",
      "      grapes       1.00      1.00      1.00        20\n",
      "        jute       1.00      0.70      0.82        20\n",
      " kidneybeans       1.00      1.00      1.00        20\n",
      "      lentil       1.00      1.00      1.00        20\n",
      "       maize       1.00      1.00      1.00        20\n",
      "       mango       1.00      1.00      1.00        20\n",
      "   mothbeans       1.00      0.95      0.97        20\n",
      "    mungbean       1.00      1.00      1.00        20\n",
      "   muskmelon       1.00      0.95      0.97        20\n",
      "      orange       1.00      1.00      1.00        20\n",
      "      papaya       1.00      0.95      0.97        20\n",
      "  pigeonpeas       1.00      1.00      1.00        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       0.77      1.00      0.87        20\n",
      "  watermelon       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.98       440\n",
      "   macro avg       0.98      0.98      0.98       440\n",
      "weighted avg       0.98      0.98      0.98       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "# Get predictions for the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "y_test_classes = np.argmax(y_test, axis=1)  # Convert one-hot encoding to class labels\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test_classes, y_pred_classes, target_names=Encoder.categories_[0])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'banana', 'blackgram', 'chickpea', 'coconut', 'coffee',\n",
       "       'cotton', 'grapes', 'jute', 'kidneybeans', 'lentil', 'maize',\n",
       "       'mango', 'mothbeans', 'mungbean', 'muskmelon', 'orange', 'papaya',\n",
       "       'pigeonpeas', 'pomegranate', 'rice', 'watermelon'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
